nohup: ignoring input
W1203 09:22:29.841000 661984 /global/u2/m/mpoona/.local/perlmutter/python-3.11/lib/python3.11/site-packages/torch/distributed/run.py:803] 
W1203 09:22:29.841000 661984 /global/u2/m/mpoona/.local/perlmutter/python-3.11/lib/python3.11/site-packages/torch/distributed/run.py:803] *****************************************
W1203 09:22:29.841000 661984 /global/u2/m/mpoona/.local/perlmutter/python-3.11/lib/python3.11/site-packages/torch/distributed/run.py:803] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1203 09:22:29.841000 661984 /global/u2/m/mpoona/.local/perlmutter/python-3.11/lib/python3.11/site-packages/torch/distributed/run.py:803] *****************************************
[rank0]:[W1203 09:23:12.336946394 reducer.cpp:1431] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[rank3]:[W1203 09:23:12.337145920 reducer.cpp:1431] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[rank1]:[W1203 09:23:12.337486679 reducer.cpp:1431] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[rank2]:[W1203 09:23:12.346260864 reducer.cpp:1431] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[rank3]: Traceback (most recent call last):
[rank3]:   File "/pscratch/sd/m/mpoona/nfl_training/train_combined.py", line 31, in <module>
[rank3]:     print(f"Best results saved to: {results.save_dir}")
[rank3]:                                     ^^^^^^^^^^^^^^^^
[rank3]: AttributeError: 'NoneType' object has no attribute 'save_dir'
[rank1]: Traceback (most recent call last):
[rank1]:   File "/pscratch/sd/m/mpoona/nfl_training/train_combined.py", line 31, in <module>
[rank1]:     print(f"Best results saved to: {results.save_dir}")
[rank1]:                                     ^^^^^^^^^^^^^^^^
[rank1]: AttributeError: 'NoneType' object has no attribute 'save_dir'
[rank2]: Traceback (most recent call last):
[rank2]:   File "/pscratch/sd/m/mpoona/nfl_training/train_combined.py", line 31, in <module>
[rank2]:     print(f"Best results saved to: {results.save_dir}")
[rank2]:                                     ^^^^^^^^^^^^^^^^
[rank2]: AttributeError: 'NoneType' object has no attribute 'save_dir'
[rank0]:[W1203 12:40:47.622008987 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
W1203 12:40:49.642000 661984 /global/u2/m/mpoona/.local/perlmutter/python-3.11/lib/python3.11/site-packages/torch/distributed/elastic/multiprocessing/api.py:908] Sending process 662090 closing signal SIGTERM
W1203 12:40:49.821000 661984 /global/u2/m/mpoona/.local/perlmutter/python-3.11/lib/python3.11/site-packages/torch/distributed/elastic/multiprocessing/api.py:908] Sending process 662091 closing signal SIGTERM
W1203 12:40:49.881000 661984 /global/u2/m/mpoona/.local/perlmutter/python-3.11/lib/python3.11/site-packages/torch/distributed/elastic/multiprocessing/api.py:908] Sending process 662092 closing signal SIGTERM
E1203 12:40:51.584000 661984 /global/u2/m/mpoona/.local/perlmutter/python-3.11/lib/python3.11/site-packages/torch/distributed/elastic/multiprocessing/api.py:882] failed (exitcode: 1) local_rank: 3 (pid: 662093) of binary: /global/common/software/nersc/pe/conda-envs/24.1.0/python-3.11/nersc-python/bin/python3.11
Traceback (most recent call last):
  File "/global/homes/m/mpoona/.local/perlmutter/python-3.11/bin/torchrun", line 8, in <module>
    sys.exit(main())
             ^^^^^^
  File "/global/homes/m/mpoona/.local/perlmutter/python-3.11/lib/python3.11/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/global/homes/m/mpoona/.local/perlmutter/python-3.11/lib/python3.11/site-packages/torch/distributed/run.py", line 936, in main
    run(args)
  File "/global/homes/m/mpoona/.local/perlmutter/python-3.11/lib/python3.11/site-packages/torch/distributed/run.py", line 927, in run
    elastic_launch(
  File "/global/homes/m/mpoona/.local/perlmutter/python-3.11/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 156, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/global/homes/m/mpoona/.local/perlmutter/python-3.11/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 293, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
train_combined.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-12-03_12:40:49
  host      : nid001224-hsn0
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 662093)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
Command exited with non-zero status 1
111947.66user 11772.84system 3:18:32elapsed 1038%CPU (0avgtext+0avgdata 10108672maxresident)k
12575504inputs+19940816outputs (2404100241major+477265396minor)pagefaults 0swaps
