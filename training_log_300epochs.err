W1202 19:34:05.565000 332644 /global/u2/m/mpoona/.local/perlmutter/python-3.11/lib/python3.11/site-packages/torch/distributed/run.py:803] 
W1202 19:34:05.565000 332644 /global/u2/m/mpoona/.local/perlmutter/python-3.11/lib/python3.11/site-packages/torch/distributed/run.py:803] *****************************************
W1202 19:34:05.565000 332644 /global/u2/m/mpoona/.local/perlmutter/python-3.11/lib/python3.11/site-packages/torch/distributed/run.py:803] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1202 19:34:05.565000 332644 /global/u2/m/mpoona/.local/perlmutter/python-3.11/lib/python3.11/site-packages/torch/distributed/run.py:803] *****************************************
[rank0]:[W1202 19:34:45.926705697 reducer.cpp:1431] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[rank3]:[W1202 19:34:46.598088088 reducer.cpp:1431] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[rank2]:[W1202 19:34:46.634497778 reducer.cpp:1431] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[rank1]:[W1202 19:34:46.658034583 reducer.cpp:1431] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
/global/homes/m/mpoona/.local/perlmutter/python-3.11/lib/python3.11/site-packages/ultralytics/utils/metrics.py:74: UserWarning: Specified kernel cache directory could not be created! This disables kernel caching. Specified directory is /global/homes/m/mpoona/.cache/torch/kernels. This warning will appear only once per process. (Triggered internally at /pytorch/aten/src/ATen/native/cuda/jit_utils.cpp:1487.)
  inter = (torch.min(a2, b2) - torch.max(a1, b1)).clamp_(0).prod(2)
/global/homes/m/mpoona/.local/perlmutter/python-3.11/lib/python3.11/site-packages/ultralytics/utils/metrics.py:74: UserWarning: Specified kernel cache directory could not be created! This disables kernel caching. Specified directory is /global/homes/m/mpoona/.cache/torch/kernels. This warning will appear only once per process. (Triggered internally at /pytorch/aten/src/ATen/native/cuda/jit_utils.cpp:1487.)
  inter = (torch.min(a2, b2) - torch.max(a1, b1)).clamp_(0).prod(2)
/global/homes/m/mpoona/.local/perlmutter/python-3.11/lib/python3.11/site-packages/ultralytics/utils/metrics.py:74: UserWarning: Specified kernel cache directory could not be created! This disables kernel caching. Specified directory is /global/homes/m/mpoona/.cache/torch/kernels. This warning will appear only once per process. (Triggered internally at /pytorch/aten/src/ATen/native/cuda/jit_utils.cpp:1487.)
  inter = (torch.min(a2, b2) - torch.max(a1, b1)).clamp_(0).prod(2)
[rank2]: Traceback (most recent call last):
[rank2]:   File "/pscratch/sd/m/mpoona/nfl_training/train_combined.py", line 31, in <module>
[rank2]:     print(f"Best results saved to: {results.save_dir}")
[rank2]:                                     ^^^^^^^^^^^^^^^^
[rank2]: AttributeError: 'NoneType' object has no attribute 'save_dir'
[rank3]: Traceback (most recent call last):
[rank3]:   File "/pscratch/sd/m/mpoona/nfl_training/train_combined.py", line 31, in <module>
[rank3]:     print(f"Best results saved to: {results.save_dir}")
[rank3]:                                     ^^^^^^^^^^^^^^^^
[rank3]: AttributeError: 'NoneType' object has no attribute 'save_dir'
[rank1]: Traceback (most recent call last):
[rank1]:   File "/pscratch/sd/m/mpoona/nfl_training/train_combined.py", line 31, in <module>
[rank1]:     print(f"Best results saved to: {results.save_dir}")
[rank1]:                                     ^^^^^^^^^^^^^^^^
[rank1]: AttributeError: 'NoneType' object has no attribute 'save_dir'
[rank0]:[W1202 19:49:31.185834514 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
W1202 19:49:34.004000 332644 /global/u2/m/mpoona/.local/perlmutter/python-3.11/lib/python3.11/site-packages/torch/distributed/elastic/multiprocessing/api.py:908] Sending process 332794 closing signal SIGTERM
W1202 19:49:34.036000 332644 /global/u2/m/mpoona/.local/perlmutter/python-3.11/lib/python3.11/site-packages/torch/distributed/elastic/multiprocessing/api.py:908] Sending process 332795 closing signal SIGTERM
W1202 19:49:34.074000 332644 /global/u2/m/mpoona/.local/perlmutter/python-3.11/lib/python3.11/site-packages/torch/distributed/elastic/multiprocessing/api.py:908] Sending process 332796 closing signal SIGTERM
E1202 19:49:36.459000 332644 /global/u2/m/mpoona/.local/perlmutter/python-3.11/lib/python3.11/site-packages/torch/distributed/elastic/multiprocessing/api.py:882] failed (exitcode: 1) local_rank: 3 (pid: 332797) of binary: /global/common/software/nersc/pe/conda-envs/24.1.0/python-3.11/nersc-python/bin/python3.11
Traceback (most recent call last):
  File "/global/homes/m/mpoona/.local/perlmutter/python-3.11/bin/torchrun", line 8, in <module>
    sys.exit(main())
             ^^^^^^
  File "/global/homes/m/mpoona/.local/perlmutter/python-3.11/lib/python3.11/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 357, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/global/homes/m/mpoona/.local/perlmutter/python-3.11/lib/python3.11/site-packages/torch/distributed/run.py", line 936, in main
    run(args)
  File "/global/homes/m/mpoona/.local/perlmutter/python-3.11/lib/python3.11/site-packages/torch/distributed/run.py", line 927, in run
    elastic_launch(
  File "/global/homes/m/mpoona/.local/perlmutter/python-3.11/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 156, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/global/homes/m/mpoona/.local/perlmutter/python-3.11/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 293, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
train_combined.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-12-02_19:49:34
  host      : nid001144-hsn0
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 332797)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
